# 🏗️ News Portal 시스템 아키텍처 가이드

이 프로젝트는 4개의 핵심 서비스가 유기적으로 맞물려 돌아가는 **완전 자동화 뉴스 파이프라인**입니다.

**🌐 공식 서비스 주소**: [https://aesthetics-intelligence.vercel.app/](https://aesthetics-intelligence.vercel.app/)

---

### 🧠 Antigravity Intelligence (MCP & Extensions)

현재 시스템은 다음과 같은 지능형 도구들을 통해 관리되고 확장됩니다:

* **MCP (Model Context Protocol)**: Google Cloud Run 및 Firebase MCP를 통해 서버 인프라를 실시간으로 모니터링하고 제어합니다.
* **Browser Subagents**: 주기적으로 실제 웹사이트에 접속하여 시각적 오류나 기능 결함을 검수합니다.
* **Cloud Failover**: AI 할당량 소진 시 Groq, Ollama 등으로 자동 전환되는 지능형 라우팅이 적용되어 있습니다.

---

### 1. 서비스별 역할 상세 설명

| 서비스명 | 이미지 | 핵심 역할 | 비유 |
| :--- | :---: | :--- | :--- |
| **GitHub Actions** | ⚙️ | **스케줄러 & 일꾼**<br>30분마다 깨어나서 파이썬 코드를 실행합니다. | **부지런한 배달원**<br>(아침마다 신문을 배달함) |
| **Supabase** | 🗄️ | **데이터베이스 (DB)**<br>수집된 모든 뉴스 데이터를 안전하게 저장합니다. | **거대한 책장**<br>(모든 정보를 기록해둠) |
| **Vercel** | 🌐 | **웹 호스팅 (Frontend)**<br>우리가 보는 웹사이트 화면을 전 세계에 뿌려줍니다. | **깔끔한 전광판**<br>(책장의 정보를 보기 좋게 표시) |
| **Google Sheets** | 📊 | **백업 및 관리 데이터**<br>누구나 보기 편하게 엑셀 형태로 뉴스를 기록합니다. | **종이 장부**<br>(확인 및 공유가 편함) |

---

### 2. 뉴스 데이터의 여행 (Data Flow)

뉴스가 수집되어 화면에 나오기까지의 5단계 과정입니다:

1. **[수집] GitHub Actions**가 깨어나 네이버에서 최신 뉴스를 긁어옵니다. (`async_collector.py`)
2. **[임시저장]** 수집된 원본 뉴스를 **Supabase**의 `raw_news` 테이블에 임시로 쌓아둡니다.
3. **[분석] AI(Gemini/Groq)**가 임시 저장된 뉴스를 읽고 한 줄 요약과 카테고리를 결정합니다. (`processor.py`)
4. **[최종등록]** 분석이 끝난 예쁜 뉴스를 **Supabase**의 `articles` 테이블과 **Google Sheets**에 동시에 저장합니다.
5. **[조회]** 사용자가 웹사이트에 접속하면, **Vercel** 서버가 **Supabase**의 최신 뉴스 20개를 가져와 화면에 보여줍니다.

---

### 3. 왜 이렇게 복잡하게 나누었나요? (장점)

* **100% 무료 유지**: 각 서비스의 무료 할당량만 영리하게 사용하여 운영비가 **0원**입니다.
* **컴퓨터를 꺼도 됨**: 모든 작업이 내 컴퓨터가 아닌 **GitHub/Vercel 클라우드** 상에서 일어납니다.
* **안정성**: 만약 AI가 죽더라도(Gemini 할당량 초과), 다른 모델(Groq)로 즉시 교체되어 시스템이 멈추지 않습니다.
* **편의성**: 개발자가 아니어도 **구글 시트**만 열면 뉴스가 업데이트되는 것을 실시간으로 확인할 수 있습니다.

---

### 🛠️ 관리 포인트

* **뉴스 키워드 변경**: `collector/.env` 파일의 `KEYWORDS`만 수정하면 됩니다.
* **디자인 수정**: `web/` 폴더의 코드를 고치고 GitHub에 올리면 **Vercel**이 자동으로 다시 배포합니다.
