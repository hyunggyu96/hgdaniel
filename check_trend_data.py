import os
import json
from supabase import create_client
from dotenv import load_dotenv

load_dotenv('collector/.env')
load_dotenv('.env.local')

SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY")
supabase = create_client(SUPABASE_URL, SUPABASE_KEY)

# ì¹´í…Œê³ ë¦¬ ì„¤ì • (api/trends/route.tsì™€ ë™ì¼í•´ì•¼ í•¨)
# constants.ts ë‚´ìš©ì„ ëª¨ë¥¼ ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ í•˜ë“œì½”ë”©í•˜ì§€ ì•Šê³  ì¶”ë¡ í•˜ì§€ë§Œ, 
# ì—¬ê¸°ì„œëŠ” ì¼ë°˜ì ì¸ í‚¤ì›Œë“œ ë§¤ì¹­ ë¡œì§ í…ŒìŠ¤íŠ¸
CATEGORIES_CONFIG = [
    {"label": "Filler", "keywords": ["í•„ëŸ¬", "íˆì•Œë£¨ë¡ ì‚°", "HAí•„ëŸ¬"]},
    {"label": "Botulinum Toxin", "keywords": ["í†¡ì‹ ", "ë³´í†¡ìŠ¤", "ì´ë…¸í†¡ìŠ¤", "ë©”ë””í†¡ì‹ "]},
    # ...
]

print("ğŸ” DB ìµœì‹  ë°ì´í„° 5ê°œ ì¡°íšŒ ì¤‘...")
# ì˜¤ëŠ˜ ë‚ ì§œ ê·¼ì²˜ ë°ì´í„° ì¡°íšŒ
res = supabase.table('articles').select('*').order('published_at', desc=True).limit(5).execute()
articles = res.data

if not articles:
    print("âŒ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤! DBê°€ ë¹„ì–´ìˆë‚˜ìš”?")
    exit()

print(f"ğŸ“Š ì´ {len(articles)}ê°œ ë°ì´í„° í™•ì¸\n")

for i, art in enumerate(articles):
    print(f"[{i+1}] {art.get('title')[:30]}...")
    print(f"    - Date: {art.get('published_at')}")
    print(f"    - Keyword (DB): '{art.get('keyword')}'")
    
    # ë§¤ì¹­ í…ŒìŠ¤íŠ¸
    matched = False
    for cat in CATEGORIES_CONFIG:
        if art.get('keyword') in cat['keywords']:
            print(f"    âœ… Match Category: {cat['label']} (By Exact Keyword)")
            matched = True
            break
        # ì œëª© ë§¤ì¹­ ë“± API ë¡œì§ í‰ë‚´
        elif any(k in art.get('title', '') for k in cat['keywords']):
             print(f"    âš ï¸ Title Match: {cat['label']} (API might count this, score=50)")
             matched = True
             break
             
    if not matched:
        print("    âŒ NO MATCH! (ì´ ë°ì´í„°ëŠ” ì°¨íŠ¸ì—ì„œ 0ìœ¼ë¡œ ì§‘ê³„ë¨)")
        
print("\n--- ë¶„ì„ ì¢…ë£Œ ---")
