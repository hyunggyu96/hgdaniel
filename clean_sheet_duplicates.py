"""êµ¬ê¸€ì‹œíŠ¸ ì¤‘ë³µ ë°ì´í„° ì •ë¦¬ ìŠ¤í¬ë¦½íŠ¸"""
import gspread
from oauth2client.service_account import ServiceAccountCredentials
import os

# ì„¤ì •
SERVICE_ACCOUNT_FILE = os.path.join(os.path.dirname(__file__), 'collector', 'service_account.json')
GOOGLE_SHEET_URL = "https://docs.google.com/spreadsheets/d/1IDFVtmhu5EtxSacRqlklZo6V_x9aB0WVZIzkIx5Wkic"

def clean_duplicates():
    # êµ¬ê¸€ì‹œíŠ¸ ì—°ê²°
    scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
    creds = ServiceAccountCredentials.from_json_keyfile_name(SERVICE_ACCOUNT_FILE, scope)
    client = gspread.authorize(creds)
    sheet = client.open_by_url(GOOGLE_SHEET_URL)
    # ë°˜ë“œì‹œ ì´ë¦„ìœ¼ë¡œ ì°¾ê¸° (ì¸ë±ìŠ¤ ìœ„í—˜)
    try:
        worksheet = sheet.worksheet("Synced_Articles")
        print("âœ… íƒ€ê²Ÿ ì‹œíŠ¸: Synced_Articles")
    except:
        print("âš ï¸ Synced_Articles íƒ­ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤! (Sheet1 ì‚¬ìš© ì‹œë„)")
        worksheet = sheet.get_worksheet(0)
    
    # ëª¨ë“  ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    all_data = worksheet.get_all_values()
    header = all_data[0]
    rows = all_data[1:]
    
    print(f"ğŸ“Š ì „ì²´ í–‰ ìˆ˜: {len(rows)}ê°œ")
    
    # ì´ˆê¸°í™”
    seen_links = set()
    unique_rows = []
    
    # í•„í„° ë¦¬ìŠ¤íŠ¸ ì •ì˜ (ê°•ë ¥ ì°¨ë‹¨)
    CAR_BRANDS = ["ë¥´ë…¸ì½”ë¦¬ì•„", "ë¥´ë…¸ì‚¼ì„±", "í˜„ëŒ€ì°¨", "ê¸°ì•„ì°¨", "ìŒìš©ì°¨", "KGëª¨ë¹Œë¦¬í‹°", "ì‰ë³´ë ˆ", "í­ìŠ¤ë°”ê²", "ë©”ë¥´ì„¸ë°ìŠ¤", "ë²¤ì¸ ", "BMW", "ì•„ë¥´ì¹´ë‚˜", "í† ë ˆìŠ¤", "ê·¸ëœì €", "ì œë„¤ì‹œìŠ¤", "í…ŒìŠ¬ë¼"]
    NOISE_KEYWORDS = ["ì‹œìŠ¹ê¸°", "ìë™ì°¨ ë¦¬ì½œ", "íƒ€ì´ì–´ êµì²´", "ì¤‘ê³ ì°¨", "ì „ê¸°ì°¨", "ìˆ˜ì†Œì°¨", "ë„ë¡œê³µì‚¬", "ë¸”ë™ë°•ìŠ¤", "ë‹¹êµ¬(PBA)", "í”„ë¡œë†êµ¬", "í”„ë¡œë°°êµ¬"]
    BAD_KEYWORDS = ["ìºì‹œì›Œí¬", "ìºì‹œë‹¥", "ìš©ëˆí€´ì¦ˆ", "ëˆë²„ëŠ”í€´ì¦ˆ", "ì •ë‹µ", "í€´ì¦ˆ", "ì‹ ì°¨", "SUV", "A-í•„ëŸ¬", "B-í•„ëŸ¬", "C-í•„ëŸ¬", "ë””ì§€í„¸í‚¤"]

    duplicates = 0
    filtered_count = 0
    
    for row in rows:
        keyword = row[1] if len(row) > 1 else ""
        title = row[2] if len(row) > 2 else ""
        link = row[3] if len(row) > 3 else ""
        full_text = f"{keyword} {title}"
        
        # 1. ë…¸ì´ì¦ˆ í•„í„°ë§
        is_noise = False
        if any(b in full_text for b in CAR_BRANDS): is_noise = True
        elif any(n in full_text for n in NOISE_KEYWORDS): is_noise = True
        elif any(bad in title for bad in BAD_KEYWORDS): is_noise = True
        
        if is_noise:
            filtered_count += 1
            print(f"ğŸ—‘ï¸ [ë…¸ì´ì¦ˆ ì œê±°] {title[:30]}...")
            continue

        # 2. ë§í¬ ì¤‘ë³µ í•„í„°ë§
        if link and link not in seen_links:
            seen_links.add(link)
            unique_rows.append(row)
        else:
            duplicates += 1
    
    print(f"ğŸ” ì¤‘ë³µ ë°œê²¬: {duplicates}ê°œ")
    print(f"ğŸš« ë…¸ì´ì¦ˆ ì œê±°: {filtered_count}ê°œ")
    
    print(f"ğŸ” ì¤‘ë³µ ë°œê²¬: {duplicates}ê°œ")
    print(f"âœ… ì •ë¦¬ í›„ ë‚¨ì„ í–‰: {len(unique_rows)}ê°œ")
    
    if duplicates == 0:
        print("ì •ë¦¬í•  ì¤‘ë³µì´ ì—†ìŠµë‹ˆë‹¤!")
        return
    
    # ìë™ ì‹¤í–‰ (ì‚¬ìš©ì í™•ì¸ ìƒëµ)
    print("ğŸš€ ì¦‰ì‹œ ì •ë¦¬ ì‹œì‘!")
    
    # ì‹œíŠ¸ ì •ë¦¬ (í—¤ë” ì œì™¸í•˜ê³  ëª¨ë“  ë°ì´í„° ì‚­ì œ í›„ ì¬ì…ë ¥)
    print("ğŸ”„ ì‹œíŠ¸ ì •ë¦¬ ì¤‘...")
    
    # ê¸°ì¡´ ë°ì´í„° ì‚­ì œ (í—¤ë” ì œì™¸)
    if len(rows) > 0:
        worksheet.delete_rows(2, len(rows) + 1)
    
    # ìœ ë‹ˆí¬ ë°ì´í„° ì¬ì…ë ¥ (ì—­ìˆœìœ¼ë¡œ - ìµœì‹ ì´ ìœ„ë¡œ)
    for row in reversed(unique_rows):
        worksheet.insert_row(row, 2)
    
    print(f"âœ… ì™„ë£Œ! {len(unique_rows)}ê°œ í–‰ìœ¼ë¡œ ì •ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    clean_duplicates()
